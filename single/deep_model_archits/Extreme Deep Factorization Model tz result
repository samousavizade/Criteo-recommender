digraph {
	graph [size="24.15,24.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139879122699664 [label="
 (2725)" fillcolor=darkolivegreen1]
	139879122688752 [label=SigmoidBackward0]
	139879122688848 -> 139879122688752
	139879122688848 [label=SqueezeBackward1]
	139879122688512 -> 139879122688848
	139879122688512 [label=AddBackward0]
	139879122688896 -> 139879122688512
	139879122688896 [label=AddBackward0]
	139879122689040 -> 139879122688896
	139879122689040 [label=AddBackward0]
	139879122689184 -> 139879122689040
	139879122689184 [label=SumBackward1]
	139879122689328 -> 139879122689184
	139879122689328 [label=EmbeddingBackward0]
	139879122689424 -> 139879122689328
	139879177268336 [label="linear.fc.weight
 (1944, 1)" fillcolor=lightblue]
	139879177268336 -> 139879122689424
	139879122689424 [label=AccumulateGrad]
	139879122689136 -> 139879122689040
	139879177268976 [label="linear.bias
 (1)" fillcolor=lightblue]
	139879177268976 -> 139879122689136
	139879122689136 [label=AccumulateGrad]
	139879122688992 -> 139879122688896
	139879122688992 [label=AddmmBackward0]
	139879122689376 -> 139879122688992
	139879179753968 [label="cin.fc.bias
 (1)" fillcolor=lightblue]
	139879179753968 -> 139879122689376
	139879122689376 [label=AccumulateGrad]
	139879122689520 -> 139879122688992
	139879122689520 [label=SumBackward1]
	139879122689472 -> 139879122689520
	139879122689472 [label=CatBackward0]
	139879122689664 -> 139879122689472
	139879122689664 [label=ReluBackward0]
	139879122689808 -> 139879122689664
	139879122689808 [label=SqueezeBackward1]
	139879122689904 -> 139879122689808
	139879122689904 [label=MkldnnConvolutionBackward0]
	139879122690000 -> 139879122689904
	139879122690000 [label=UnsqueezeBackward0]
	139879122639264 -> 139879122690000
	139879122639264 [label=ViewBackward0]
	139879122638640 -> 139879122639264
	139879122638640 [label=MulBackward0]
	139879122727072 -> 139879122638640
	139879122727072 [label=UnsqueezeBackward0]
	139879122727216 -> 139879122727072
	139879122727216 [label=EmbeddingBackward0]
	139879122727312 -> 139879122727216
	139879299946672 [label="embedding.embedding.weight
 (1944, 16)" fillcolor=lightblue]
	139879299946672 -> 139879122727312
	139879122727312 [label=AccumulateGrad]
	139879122727024 -> 139879122638640
	139879122727024 [label=UnsqueezeBackward0]
	139879122727216 -> 139879122727024
	139879122689952 -> 139879122689904
	139879122689952 [label=UnsqueezeBackward0]
	139879122638976 -> 139879122689952
	139879299946512 [label="cin.conv_layers.0.weight
 (16, 196, 1)" fillcolor=lightblue]
	139879299946512 -> 139879122638976
	139879122638976 [label=AccumulateGrad]
	139879122689712 -> 139879122689904
	139879299946352 [label="cin.conv_layers.0.bias
 (16)" fillcolor=lightblue]
	139879299946352 -> 139879122689712
	139879122689712 [label=AccumulateGrad]
	139879122689616 -> 139879122689472
	139879122689616 [label=ReluBackward0]
	139879122689856 -> 139879122689616
	139879122689856 [label=SqueezeBackward1]
	139879122639120 -> 139879122689856
	139879122639120 [label=MkldnnConvolutionBackward0]
	139879122726976 -> 139879122639120
	139879122726976 [label=UnsqueezeBackward0]
	139879122727456 -> 139879122726976
	139879122727456 [label=ViewBackward0]
	139879122727552 -> 139879122727456
	139879122727552 [label=MulBackward0]
	139879122727072 -> 139879122727552
	139879122727648 -> 139879122727552
	139879122727648 [label=UnsqueezeBackward0]
	139879122689664 -> 139879122727648
	139879122727264 -> 139879122639120
	139879122727264 [label=UnsqueezeBackward0]
	139879122727600 -> 139879122727264
	139879299944752 [label="cin.conv_layers.1.weight
 (16, 224, 1)" fillcolor=lightblue]
	139879299944752 -> 139879122727600
	139879122727600 [label=AccumulateGrad]
	139879122727408 -> 139879122639120
	139879299945552 [label="cin.conv_layers.1.bias
 (16)" fillcolor=lightblue]
	139879299945552 -> 139879122727408
	139879122727408 [label=AccumulateGrad]
	139879122689088 -> 139879122688992
	139879122689088 [label=TBackward0]
	139879122689760 -> 139879122689088
	139879179751968 [label="cin.fc.weight
 (1, 32)" fillcolor=lightblue]
	139879179751968 -> 139879122689760
	139879122689760 [label=AccumulateGrad]
	139879122688656 -> 139879122688512
	139879122688656 [label=AddmmBackward0]
	139879122638496 -> 139879122688656
	139879177267936 [label="mlp.mlp.8.bias
 (1)" fillcolor=lightblue]
	139879177267936 -> 139879122638496
	139879122638496 [label=AccumulateGrad]
	139879122689280 -> 139879122688656
	139879122689280 [label=ReluBackward0]
	139879122689232 -> 139879122689280
	139879122689232 [label=NativeBatchNormBackward0]
	139879122727504 -> 139879122689232
	139879122727504 [label=AddmmBackward0]
	139879122727840 -> 139879122727504
	139879177422704 [label="mlp.mlp.4.bias
 (16)" fillcolor=lightblue]
	139879177422704 -> 139879122727840
	139879122727840 [label=AccumulateGrad]
	139879122727792 -> 139879122727504
	139879122727792 [label=ReluBackward0]
	139879122727936 -> 139879122727792
	139879122727936 [label=NativeBatchNormBackward0]
	139879122728128 -> 139879122727936
	139879122728128 [label=AddmmBackward0]
	139879122728320 -> 139879122728128
	139879299955344 [label="mlp.mlp.0.bias
 (16)" fillcolor=lightblue]
	139879299955344 -> 139879122728320
	139879122728320 [label=AccumulateGrad]
	139879122728272 -> 139879122728128
	139879122728272 [label=ViewBackward0]
	139879122727216 -> 139879122728272
	139879122728224 -> 139879122728128
	139879122728224 [label=TBackward0]
	139879122728512 -> 139879122728224
	139879299954384 [label="mlp.mlp.0.weight
 (16, 224)" fillcolor=lightblue]
	139879299954384 -> 139879122728512
	139879122728512 [label=AccumulateGrad]
	139879122728080 -> 139879122727936
	139879299954864 [label="mlp.mlp.1.weight
 (16)" fillcolor=lightblue]
	139879299954864 -> 139879122728080
	139879122728080 [label=AccumulateGrad]
	139879122728032 -> 139879122727936
	139879299952944 [label="mlp.mlp.1.bias
 (16)" fillcolor=lightblue]
	139879299952944 -> 139879122728032
	139879122728032 [label=AccumulateGrad]
	139879122727360 -> 139879122727504
	139879122727360 [label=TBackward0]
	139879122728368 -> 139879122727360
	139879177423344 [label="mlp.mlp.4.weight
 (16, 16)" fillcolor=lightblue]
	139879177423344 -> 139879122728368
	139879122728368 [label=AccumulateGrad]
	139879122727696 -> 139879122689232
	139879299917760 [label="mlp.mlp.5.weight
 (16)" fillcolor=lightblue]
	139879299917760 -> 139879122727696
	139879122727696 [label=AccumulateGrad]
	139879122727744 -> 139879122689232
	139879177267536 [label="mlp.mlp.5.bias
 (16)" fillcolor=lightblue]
	139879177267536 -> 139879122727744
	139879122727744 [label=AccumulateGrad]
	139879122688944 -> 139879122688656
	139879122688944 [label=TBackward0]
	139879122727888 -> 139879122688944
	139879177267856 [label="mlp.mlp.8.weight
 (1, 16)" fillcolor=lightblue]
	139879177267856 -> 139879122727888
	139879122727888 [label=AccumulateGrad]
	139879122688752 -> 139879122699664
}
